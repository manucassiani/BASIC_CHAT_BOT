from llama_index.core.query_engine import BaseQueryEngine


class ChatService:
    """
    A service class to handle chat interactions using a query engine.

    This class wraps around a BaseQueryEngine to facilitate querying and
    retrieving responses based on user input.
    """

    def __init__(
        self,
        engine: BaseQueryEngine,
    ):
        self.engine = engine

    def chat(self, user_input: str) -> str:
        """Processes user input through the query engine and returns the response.

        Args:
            user_input (str): The input string from the user.

        Returns:
            str: The response generated by the query engine.
        """

        # Pass the user input to the query engine and retrieve the response
        response = self.engine.query(str_or_query_bundle=user_input).response

        return response
